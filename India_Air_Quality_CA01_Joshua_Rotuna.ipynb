{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "India_Air_Quality_CA01_Joshua_Rotuna.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKEnF5cO8t0v"
      },
      "source": [
        "#Joshua Rotuna\n",
        "## Assignment Name: CA01 - Data Cleaning and Exploration of India Air Quality\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyWkXYFH8t0x"
      },
      "source": [
        "# Program Inititialization Section\n",
        "## Enter your import packages here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5W2pFIzJ8t0y"
      },
      "source": [
        "# import packages \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6PToDjt8t0y"
      },
      "source": [
        "# Data File Reading Section\n",
        "## Write code to read in data from external sources here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M47H7rA8t0y"
      },
      "source": [
        "#read datasets\n",
        "india = pd.read_csv('india_data_3.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPJBfZsn8t0z"
      },
      "source": [
        "# Initial Data Investigation Section\n",
        "\n",
        "## Summarized details\n",
        "### Generate descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN values.\n",
        "#### Steps:\n",
        "#### 1. Statistical Description of data (data.describe)\n",
        "#### 2. Display number of total rows and columns of the dataset (data.shape)\n",
        "#### 3. Display number of non-null values for each column (data.count)\n",
        "#### 4. Display number of null values for each column (sum of data.isnull)\n",
        "#### 5. Display range, column, number of non-null objects of each column, datatype and memory usage (data.info)\n",
        "#### 6. Display Top 10 and Bottom 10 records (head and tail)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JwGiaC598t01"
      },
      "source": [
        "# Summary Details\n",
        "\n",
        "india.describe()\n",
        "india.shape\n",
        "india.count()\n",
        "india.isnull().sum()\n",
        "india.info()\n",
        "india.head(10)\n",
        "india.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIRH6a10hTM8"
      },
      "source": [
        "# Adding new Year Column:\n",
        "india.date = pd.to_datetime(india.date)\n",
        "india['year'] = india.date.dt.year\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBGD8lJm8t02"
      },
      "source": [
        "## Cleansing the dataset\n",
        "### Dropping of less valued columns:\n",
        "1. stn_code, agency, sampling_date, location_monitoring_agency do not add much value to the dataset in terms of information. Therefore, we can drop those columns.\n",
        "\n",
        "2. Dropping rows where no date is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdR0sm6O8t02"
      },
      "source": [
        "# Cleaning up the data\n",
        "#dropping columns that aren't required\n",
        "india = india.drop(['stn_code', 'agency', 'sampling_date', 'location_monitoring_station'], axis =1 )\n",
        "\n",
        "# dropping rows where no date is available\n",
        "india = india[india['date'].notna()]\n",
        "india.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnIAe0SP8t02"
      },
      "source": [
        "# displaying final columns (data.columns)\n",
        "india.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGlY448c8t03"
      },
      "source": [
        "### Changing the types to uniform format:\n",
        "\n",
        "Notice that the ‘type’ column has values such as ‘Industrial Area’ and ‘Industrial Areas’ — both actually mean the same, so let’s remove such type of stuff and make it uniform. Replace the 'type' values with standard codes as follows:\n",
        "\n",
        "types = {\n",
        "    \"Residential\": \"R\",\n",
        "    \"Residential and others\": \"RO\",\n",
        "    \"Residential, Rural and other Areas\": \"RRO\",\n",
        "    \"Industrial Area\": \"I\",\n",
        "    \"Industrial Areas\": \"I\",\n",
        "    \"Industrial\": \"I\",\n",
        "    \"Sensitive Area\": \"S\",\n",
        "    \"Sensitive Areas\": \"S\",\n",
        "    \"Sensitive\": \"S\",\n",
        "    np.nan: \"RRO\"\n",
        "}\n",
        "\n",
        "data.type = data.type.replace(types)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDwOsJyB8t03"
      },
      "source": [
        "india.type = india.type.replace({ \"Residential\": \"R\", \"Residential and others\": \"RO\", \"Residential, Rural and other Areas\": \"RRO\", \"Industrial Area\": \"I\", \"Industrial Areas\": \"I\", \"Industrial\": \"I\", \"Sensitive Area\": \"S\", \"Sensitive Areas\": \"S\", \"Sensitive\": \"S\", np.nan: \"RRO\" })\n",
        "india.type.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61h7p_-R8t03"
      },
      "source": [
        "# Display top 10 records after codification of 'types'\n",
        "india.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "179fD-ap8t04"
      },
      "source": [
        "### Creating a year column\n",
        "To view the trend over a period of time, we need year values for each row and also when you see in most of the values in date column only has ‘year’ value. So, let’s create a new column holding year values. Convert the column to 'datetime' type and extract the year to populate the new column. Display Top 5 records after the conversion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzEYPp-48t04"
      },
      "source": [
        "india.date = pd.to_datetime(india.date)\n",
        "india['year'] = india.date.dt.year\n",
        "india.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-roqiyyr8t04"
      },
      "source": [
        "### Handling Missing Values\n",
        "\n",
        "The column such as SO2, NO2, rspm, spm, pm2_5 are the ones which contribute much to our analysis. So, we need to remove null from those columns to avoid inaccuracy in the prediction.\n",
        "We use the Imputer from sklearn.preprocessing to fill the missing values in every column with the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "SpN6r1nr8t04"
      },
      "source": [
        "# define columns of importance, which shall be used reguarly (COLS = ....)\n",
        "# invoke SimpleImputer to fill missing values using 'mean' as the replacement strategy\n",
        "# Display data.info after the transformation\n",
        "# Display that there are no more missing values in the dataset\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy = 'mean')\n",
        "\n",
        "# Defining columns of importance\n",
        "cols = 'so2', 'no2', 'rspm', 'spm', 'pm2_5'\n",
        "\n",
        "# Use SimpleImputer to fill missing values with 'mean' as the strategy\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "india[['so2', 'no2', 'rspm', 'spm', 'pm2_5']] = imputer.fit_transform(india[['so2', 'no2', 'rspm', 'spm', 'pm2_5']])\n",
        "\n",
        "# Display data.info after the transformation\n",
        "india.info()\n",
        "\n",
        "# Display that there are no more missing values in the dataset\n",
        "india.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_fonnIx8t05"
      },
      "source": [
        "## Statewise Grouping of so2, no2, rspm, spm values\n",
        "\n",
        "Calculate median values of so2, no2, rspm, spm for each state and display in (a) as table (b) bar chart, with values sorted in ascending order. Separate section for each of the component. Use matplotlib()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0q8fmD-8t05"
      },
      "source": [
        "### so2 status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49qxEFs8t05"
      },
      "source": [
        "so2 = india.groupby('state').so2.median().sort_values(ascending=False)\n",
        "so2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJE1gNuPCGXl"
      },
      "source": [
        "# SO2 Bar Chart By State\n",
        "plt.bar(so2.index,so2)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('SO2 levels since 1990 by State')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('SO2 Level')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02SCQEcy8t05"
      },
      "source": [
        "### no2 status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUu_q7m8t06"
      },
      "source": [
        "no2 = india.groupby('state').no2.median().sort_values(ascending=False)\n",
        "no2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6Tpf8GCTKu"
      },
      "source": [
        "# NO2 Bar Chart\n",
        "plt.bar(no2.index, no2)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('NO2 levels since 1990 by State')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('NO2 Level')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcBKgFGi8t06"
      },
      "source": [
        "### rspm status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAf9WCI8t06"
      },
      "source": [
        "rspm = india.groupby('state').rspm.median().sort_values(ascending=False)\n",
        "rspm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UHKIV5HClim"
      },
      "source": [
        "# RSMP Bar Chart By State\n",
        "plt.bar(rspm.index,rspm)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('RSPM levels since 1990 by State')\n",
        "plt.xlabel('Stata')\n",
        "plt.ylabel('RSMP Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FwLqcM38t06"
      },
      "source": [
        "### spm status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waNuxUjb8t07"
      },
      "source": [
        "spm = india.groupby('state').spm.median().sort_values(ascending=False)\n",
        "spm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biQMFa6ZCuPM"
      },
      "source": [
        "# SPM Bar Chart by State\n",
        "plt.bar(spm.index, spm)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('SPM levels since 1990 by State')\n",
        "plt.xlabel('State')\n",
        "plt.ylabel('SPM level')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0hn0LGp8t07"
      },
      "source": [
        "### What is the yearly trend in a particular state, say ‘Andhra Pradesh’?\n",
        "\n",
        "Create a new dataframe containing the NO2, SO2, rspm, and spm data regarding state ‘Andhra Pradesh’ only and group it by ‘year’. Display top 5 records after."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iml-fnna8t07"
      },
      "source": [
        "# Creating Dataset for Pradesh alone\n",
        "pradesh = india[india.state =='Andhra Pradesh']\n",
        "pradesh.drop(['state','type','date', 'pm2_5', 'location'], axis =1)\n",
        "\n",
        "# Grouping Pradesh by year (Top 5 years)\n",
        "pradesh_year = pradesh.groupby('year').median()\n",
        "pradesh_year.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xE9n0Qf8t07"
      },
      "source": [
        "# Display yearly trend graph (year vs. value) in pairs: (a) so2 and no2 (b) rspm and spm. \n",
        "# So, you will display TWO graphs altogether.\n",
        "\n",
        "# A.) so2 & no2\n",
        "plt.plot(pradesh_year.index, pradesh_year.so2, color ='g',linewidth = 2.5,label ='SO2')\n",
        "plt.plot(pradesh_year.index, pradesh_year.no2, linewidth = 2.5, label ='NO2')\n",
        "plt.legend()\n",
        "plt.title('SO2 & NO2 Since 1990')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Quality Levels')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9fAwke2lcDE"
      },
      "source": [
        "# B.) RSPM & SPM \n",
        "\n",
        "plt.plot(pradesh_year.index, pradesh_year.rspm, color ='c',linewidth = 2.8,label ='RSPM')\n",
        "plt.plot(pradesh_year.index, pradesh_year.spm, color = 'r',linewidth = 2.8, label ='SPM')\n",
        "plt.legend()\n",
        "plt.title('RSPM & SPM Since 1990')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Quality Levels')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkQYlglF8t08"
      },
      "source": [
        "The data indicated that the large majority of states in India observed very similar median Suspended Particulate Matter (SPM) levels. However, **Manipur** and **Sikkim** observed levels far lower than the rest of the states in India.\n",
        "\n",
        "It was interesting to find that SPM levels decreased largely from around 1995 to about 2003 in Andrah Pradesh. SPM decreased dramatically in 2002 to below 100 and this was the only year that it dropped that low.\n",
        "\n",
        "In addition, the analysis indicated that Sulfur dioxide (so2) levels have steadily decreased since about 1995 in Andrah Pradesh.\n",
        "\n",
        "Furthermore, The Respirable Suspended Particulate Matter (RSMP) remained nearly constant until 2002 where it began to decrease considerably every year overall. RSMP levels have decreased by roughly 35% total since 1990. \n",
        "\n",
        "Nitrogen Dioxide (NO2) levels have experienced considerable volatility in the years since 1990 in that its NO2 levels have observed very large increases and decreases per year."
      ]
    }
  ]
}